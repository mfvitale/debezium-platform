conductor:
  watcher:
    enabled: true
    offset:
      storage:
        type: org.apache.kafka.connect.storage.FileOffsetBackingStore
        config:
          file:
            filename: offsets.dat
      config:
        flush:
          interval:
            ms: 300
pipeline:
  offset:
    storage:
      # In the future when we will have other environment implementations the default should be re-thought.
      type: io.debezium.storage.jdbc.offset.JdbcOffsetBackingStore
      config:
        jdbc:
          url: ${OFFSET_JDBC_URL:${quarkus.datasource.jdbc.url}}
          user: ${OFFSET_JDBC_USERNAME:${quarkus.datasource.username}}
          password: ${OFFSET_JDBC_PASSWORD:${quarkus.datasource.password}}
          offset:
            table:
              name: "@{pipeline_name}_offset"
  schema:
    history:
      internal: io.debezium.storage.jdbc.history.JdbcSchemaHistory
      config:
        jdbc:
          url: ${SCHEMA_HISTORY_JDBC_URL:${quarkus.datasource.jdbc.url}}
          user: ${SCHEMA_HISTORY_JDBC_USERNAME:${quarkus.datasource.username}}
          password: ${SCHEMA_HISTORY_JDBC_PASSWORD:${quarkus.datasource.password}}
          schema:
            history:
              table:
                name: "@{pipeline_name}_schema_history"
sources:
  database:
    connection:
      timeout: 60
destinations:
  kafka:
    connection:
      timeout: 60

# Context7 MCP integration
context7:
  api-key: ${CONTEXT7_API_KEY:fake}

quarkus:
  hibernate-orm:
    mapping:
      format:
        global: ignore
  rest-client:
    debezium-server-api:
      url: http://localhost:8080
      # Avoid throwing an exception when HTTP status code is higher than 400
      disable-default-mapper: true
  http:
    cors:
        ~: true
  debezium-outbox:
    table-name: events
    aggregate-type:
      name: aggregatetype
    aggregate-id:
      name: aggregateid
    type:
      name: type
  datasource:
    db-kind: postgresql
  flyway:
    baseline-on-migrate: true
    migrate-at-start: true
  swagger-ui:
    always-include: true
  # LangChain4j Anthropic configuration
  langchain4j:
    anthropic:
      api-key: ${CHAT_OPENAI_API_KEY:fake}
      base-url: ${CHAT_OPENAI_BASE_URL:fake}
      chat-model:
        model-name: ${CHAT_OPENAI_MODEL_NAME:fake}
        log-requests: ${CHAT_LOG_REQUESTS:false}
        log-responses: ${CHAT_LOG_RESPONSES:false}
    # MCP client configurations
    mcp:
      debezium-platform:
        transport-type: streamable-http
        url: http://localhost:8081/mcp
        log-requests: ${MCP_LOG_REQUESTS:false}
        log-responses: ${MCP_LOG_RESPONSES:false}
      context7:
        transport-type: streamable-http
        url: https://mcp.context7.com/mcp
        log-requests: ${MCP_LOG_REQUESTS:false}
        log-responses: ${MCP_LOG_RESPONSES:false}
  # MCP server schema generator configuration
  mcp:
    server:
      schema-generator:
        jakarta-validation:
          enabled: true
          not-nullable-field-is-required: true
          not-nullable-method-is-required: true
          include-pattern-expressions: true
  log:
    min-level: TRACE
    level: INFO

"%dev":
  conductor:
    watcher:
      enabled: true
      crd: https://raw.githubusercontent.com/debezium/debezium-operator/main/k8/debeziumservers.debezium.io-v1.yml
      offset:
        storage:
          type: org.apache.kafka.connect.storage.FileOffsetBackingStore
          config:
            file:
              filename: offsets.dat
        config:
          flush:
            interval:
              ms: 300
  pipeline:
    offset:
      storage:
        # In the future when we will have other environment implementations the default should be re-thought.
        type: io.debezium.storage.jdbc.offset.JdbcOffsetBackingStore
        config:
          jdbc:
            url: jdbc:postgresql://postgresql:5432/debezium?loggerLevel=OFF
            user: debezium
            password: debezium
            offset:
              table:
                name: "@{pipeline_name}_offset"
    schema:
      history:
        internal: io.debezium.storage.jdbc.history.JdbcSchemaHistory
        config:
          jdbc:
            url: jdbc:postgresql://postgresql:5432/debezium?loggerLevel=OFF
            user: debezium
            password: debezium
            schema:
              history:
                table:
                  name: "@{pipeline_name}_schema_history"
  quarkus:
    debezium-outbox:
      remove-after-insert: false
    flyway:
      baseline-on-migrate: true
      migrate-at-start: true
    datasource:
      devservices:
        enabled: true
        port: 5432
        image-name: quay.io/debezium/postgres:16-alpine
    http:
      port: 8081
    log:
      level: INFO
      category:
        "io.debezium":
          level: INFO
        "io.debezium.platform.environment.actions":
          level: TRACE

"%test":
  conductor:
    watcher:
      enabled: true
      offset:
        storage:
          type: org.apache.kafka.connect.storage.MemoryOffsetBackingStore
  quarkus:
    datasource:
      devservices:
        enabled: true
        image-name: quay.io/debezium/postgres:16-alpine
    flyway:
      baseline-on-migrate: true